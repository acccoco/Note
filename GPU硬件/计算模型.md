---
tags:
    - gpu
---


GPU - 计算模型

=======================================================

精简掌握的概念：

> 硬件概念：SP，SM。SP 是具体的计算核心；SM 包含多个 SP，还有一些资源（寄存器，共享内存等）

> 软件概念：Grid，Block，Thread。Grid 包含多个 Block；Block 包含多个 Thread

> GPU 调度的概念：Warp。Warp 内包含 32 个线程，这些线程步调一致，是 GPU 调度的最小单位。一个 Warp 会被放在一个 SM 上由 Warp 调度器调度执行。

> Warp 是从 Block 中分出来的，一个 Block 可以划分出多个 Warp，一个 Block 的多个 Warp 运行在同一个 SM 上。

> SP 和 Thread 的关系：SP 是功能单元，如果 Thread 执行需要进行整数运算，那么 Warp 调度器就不会调度 SP 来计算，而是会调用 ALU 来计算。

![[-最近/_attachments/download.png]]

=======================================================

GPU 的硬件：SP，SM 是硬件的概念

-   SP：streaming processor，计算核心/Cuda Cores
-   SM：streaming multiprocessor：多个 SP，再加上其他的一些资源，组成了 SM

示意图如下：

        图中这个 SM 有 64 个 SP，有两个 Warp 调度器，64KB 大的 shared memory。


![[-最近/_attachments/download-1.png]]

软件的概念：Kernel，Grid，Block 是面向用户的概念

-   一个 kernel 程序会起一系列的线程，整体叫做 Grid
-   Grid 划分为多个 Block
-   Block 中就是多个 Thread

示意图如下：

下图共有两个 Kernel 程序，每个 Kernel 程序对应一个 Grid。 Grid 1 被划分为了 4 个块，每个块有 16 个 threads

![[-最近/_attachments/download-2.png]]

两者的关系：Warp 是 GPU 调度的一个概念

-   Block 会被分配到某个 SM 去执行
-   Block 中的任务会被划分为多个 Warp，每个 Warp 包含固定的 32 个 threads。
-   Warp 是 GPU 运行和调度的基本单位，可以将 Warp 理解为任务单元。SM 内有专门的硬件 Warp 调度器。Warp 中的线程是步调一致的。

如下图所示：

-   程序设定如下：Kernel 对应的 Grid 被分为 4 个 Block，每个 Block 内有 128 个 Threads
-   硬件规格：GPU 有 2 个SM，的每个 SM 有 64 个 SP
-   每个 Block 会被固定的一个 SM 运行，每个 Block 会被划分为 4 个 Warp（4 个任务单元）。

任务分配情况如图：


![[-最近/_attachments/download-3.png]]

Warp 调度器的原理：

        Warp 调度器会检查分配给它的一系列 Warp，看看谁能够执行，然后选择一个 Warp，执行一条指令。如果一个 SM 里只有 8 个 功能单元（SP 或者 ALU），那么需要 4 个时钟周期才能够执行外一个指令。然后 Warp 调度器选择下一个指令继续执行。

可能出现的情况：

![[-最近/_attachments/download-4.png]]

参考资源：

近距离看 GPU 计算： [https://mp.weixin.qq.com/s/eMG4luKIHY95m4w1lbaxhg](https://mp.weixin.qq.com/s/eMG4luKIHY95m4w1lbaxhg) 

深入GPU硬件架构及运行机制： [https://www.cnblogs.com/timlly/p/11471507.html](https://www.cnblogs.com/timlly/p/11471507.html)